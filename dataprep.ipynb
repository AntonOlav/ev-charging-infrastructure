{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl\n",
    "import seaborn as sns \n",
    "import geopandas as gpd\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import requests\n",
    "import shapely\n",
    "import pickle\n",
    "import progressbar\n",
    "import geopy.distance\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import itertools\n",
    "import warnings\n",
    "import random\n",
    "import timeit\n",
    "import time\n",
    "import threading\n",
    "import functions\n",
    "from joblib import Parallel, delayed\n",
    "from funcs_a import *\n",
    "from shapely.geometry import Point, Polygon, LineString \n",
    "from shapely.ops import nearest_points\n",
    "from shapely.ops import transform\n",
    "from shapely import geometry, ops\n",
    "from functools import partial\n",
    "from itertools import combinations\n",
    "from multiprocessing import Pool\n",
    "from random import choice, randint\n",
    "from scipy.sparse import lil_matrix\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph\n",
    "with open(r\"C:\\Users\\anton\\Desktop\\Master-Oppgave\\Kode\\New_Traffic\\data\\BaseGraph_E_NOR_wagrades.pickle\", 'rb') as file:\n",
    "    G = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read OD Nodes and All current ChargingStationsNodes\n",
    "OD = pd.read_csv(r\"C:\\Users\\anton\\Desktop\\Master-Oppgave\\Kode\\apert\\data\\OD_new.csv\", encoding=\"Cp1252\")\n",
    "OD = OD.drop('Unnamed: 0', axis=1)\n",
    "# OD_test = pd.read_csv(\"Data/OD_test.csv\", encoding=\"iso8859_10\")\n",
    "# OD_test = OD_test.drop('Unnamed: 0', axis=1)\n",
    "CS = pd.read_csv(r\"C:\\Users\\anton\\Desktop\\Master-Oppgave\\Kode\\apert\\data\\AllCurrentCS.csv\", encoding=\"Cp1252\")\n",
    "CS = CS.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_attrs = {'crs': 'epsg:4326', 'simplified': False}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = G.copy()\n",
    "H = H.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get nearest node to each O-D location\n",
    "lat = list(OD.lat)\n",
    "lon = list(OD.lon)\n",
    "ODs= ox.distance.nearest_nodes(H, lon, lat)\n",
    "OD['node'] = ODs\n",
    "\n",
    "#Get nearest node to each CS\n",
    "latA = list(CS.Latitude)\n",
    "lonA = list(CS.Longitude)\n",
    "AllCSnodes = ox.distance.nearest_nodes(H, lonA, latA)\n",
    "CS['node']=AllCSnodes\n",
    "AllCSnodes1 = list(CS.node)\n",
    "#Create combinations of O-D pairs. Used for several functions later on\n",
    "combos = combinations(ODs,2)\n",
    "OD_pairs = []\n",
    "for i in combos:\n",
    "    OD_pairs.append(list(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_drivetime(drivetime_values):\n",
    "    sum_drivetime = 0\n",
    "    for drivetime in drivetime_values:\n",
    "        if drivetime != -1:\n",
    "            sum_drivetime += drivetime\n",
    "    return sum_drivetime\n",
    "\n",
    "def process_length(length_values):\n",
    "    sum_length = 0\n",
    "    for length in length_values:\n",
    "        if length != -1:\n",
    "            sum_length += length\n",
    "    return sum_length\n",
    "\n",
    "\n",
    "def get_edge_attributes(cumlist):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Function that takes a list of network nodes and merge their attributes as the different attributes need to be treated and formatted differently. This specifically applies for LineString.\n",
    "    \n",
    "    Input:\n",
    "    cumlist: Cummulative list of nodes\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    cumlength = len(cumlist)\n",
    "    path_attributes = dict()\n",
    "    attrs_to_sum = {\"length\", \"drivetime\",}\n",
    "    attrs_to_set = {'oneway', 'ref', 'name', 'funcroadclass', 'roadclass'}\n",
    "    dummy_attrs = {'isFerry', 'isTunnel', 'isBridge'}\n",
    "    nodes_to_remove = []\n",
    "    \n",
    "    for i in range(cumlength-1):\n",
    "        u = cumlist[i]\n",
    "        v = cumlist[i+1]\n",
    "        edge_data = H.edges[u, v, 0]\n",
    "\n",
    "        for attr in edge_data:\n",
    "            if attr in path_attributes:\n",
    "            # if this key already exists in the dict, append it to the value list\n",
    "                path_attributes[attr].append(edge_data[attr])\n",
    "            else:\n",
    "            # if this key doesn't already exist, set the value to a list containing the one value\n",
    "                path_attributes[attr] = [edge_data[attr]]\n",
    "\n",
    "    for attr in path_attributes:\n",
    "        if attr == 'grade' or attr == 'length_weight':\n",
    "            path_attributes[attr] = list(path_attributes[attr]) \n",
    "        elif attr in dummy_attrs:\n",
    "            #If attribute is isFerry, isBridge og isTunnel, returns the value for first and last edge as these are candidate locations.\n",
    "            if type(path_attributes[attr][0]) == list and type(path_attributes[attr][-1]) == list:\n",
    "                fromnode = path_attributes[attr][0][0]\n",
    "                tonode = path_attributes[attr][-1][-1]\n",
    "                \n",
    "            elif type(path_attributes[attr][0]) != list and type(path_attributes[attr][-1]) != list:\n",
    "                fromnode = path_attributes[attr][0]\n",
    "                tonode = path_attributes[attr][-1]\n",
    "                \n",
    "            elif type(path_attributes[attr][0]) == list and type(path_attributes[attr][-1]) != list:\n",
    "                fromnode = path_attributes[attr][0][0]\n",
    "                tonode = path_attributes[attr][-1]\n",
    "                \n",
    "            elif type(path_attributes[attr][0]) != list and type(path_attributes[attr][-1]) == list:\n",
    "                fromnode = path_attributes[attr][0]\n",
    "                tonode = path_attributes[attr][-1][-1]\n",
    "            path_attributes[attr] = list((fromnode, tonode))\n",
    "\n",
    "        elif attr in attrs_to_sum:\n",
    "            if attr == 'drivetime' or attr == 'length':\n",
    "                try:\n",
    "                    flattened_values = []\n",
    "                    for value in path_attributes[attr]:\n",
    "                        if isinstance(value, (int, float)):\n",
    "                            if value != -1:\n",
    "                              flattened_values.append(value)\n",
    "                        elif isinstance(value, list):\n",
    "                            flattened_values.extend([v for v in value if v != -1])\n",
    "                    if attr == 'drivetime':\n",
    "                        path_attributes[attr] = process_drivetime(flattened_values)\n",
    "                    elif attr == 'length':\n",
    "                        path_attributes[attr] = process_length(flattened_values)\n",
    "                except TypeError:\n",
    "                    print(f\"Error summing attribute '{attr}', value: {path_attributes[attr]}\")\n",
    "\n",
    "        elif attr == 'id':\n",
    "            path_attributes[attr] = list((cumlist[0],cumlist[-1]))\n",
    "\n",
    "        \n",
    "        elif attr == 'geometry':\n",
    "                path_attributes[attr] = ops.linemerge(path_attributes[attr])\n",
    "                \n",
    "        elif attr == 'oneway':\n",
    "            path_attributes[attr] = 'False'\n",
    "\n",
    "\n",
    "        else:\n",
    "        # otherwise, if there are multiple values, keep one of each\n",
    "            try:\n",
    "                path_attributes[attr] = list(set(path_attributes[attr]))\n",
    "            except TypeError:\n",
    "                try:\n",
    "                    path_attributes[attr] = list(set(path_attributes[attr][0]))\n",
    "                except:\n",
    "                    path_attributes[attr] = path_attributes[attr]\n",
    "            \n",
    "    path_attributes['artificial'] = 1\n",
    "    return path_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_edges_v2(G, OD, cutoff):\n",
    "    \n",
    "    \"\"\"\n",
    "    Simplifies the edges in the network in order to make the runtimes of the GA/greedy substitution feassible. Depending on the threshold value, the function will remove all nodes/edges within a certain range, store and merge\n",
    "    their attributes, before creating a new edge between the first and last node in the specified range. If cutoff is for example 50000, the function will remove all nodes except the first and last node for every 50th km and \n",
    "    create a new edge between the first and last node. This i then repeated for each path between each OD pair.\n",
    "    \n",
    "    There are also certain statements to make sure that the same nodes are used if several paths intersect. This usually happens when multiple routes shares the same path. \n",
    "    \n",
    "    Input:\n",
    "    G: Networkx Multigraph\n",
    "    OD: CSV file with coordinates of each OD location in Norway\n",
    "    Threshold: Cutoff in meters at which edges at merged. \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    #Create flat list of O-D pairs\n",
    "    OD_pairs_flat = [item for sublist in OD_pairs for item in sublist]\n",
    "    \n",
    "    #Create empty MultiGraph\n",
    "    B = nx.MultiGraph(crs='epsg:4326')\n",
    "    \n",
    "    #Initialize progressbar to monitor progress of function while running.\n",
    "    maxval = len(OD_pairs)\n",
    "    bar    = progressbar.ProgressBar(maxval=maxval, \\\n",
    "        widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "\n",
    "    counter=0\n",
    "    bar.start()\n",
    "\n",
    "    UsedNodes = []\n",
    "    for i in OD_pairs:\n",
    "        fromOD         = i[0]\n",
    "        toOD           = i[1]\n",
    "        path           = nx.shortest_path(H, fromOD, toOD, 'length')\n",
    "        pathlength     = len(path)\n",
    "        lengthofpath   = nx.shortest_path_length(H, fromOD, toOD, 'length')\n",
    "        cumlength      = 0\n",
    "        cumlist        = []\n",
    "        cutoff         = cutoff\n",
    "\n",
    "\n",
    "        #for each in edge in path[i]\n",
    "        for i in range(pathlength-1):\n",
    "            fromnode = path[i]\n",
    "            tonode = path[i+1]\n",
    "            templength = H.edges[fromnode, tonode, 0]['length']\n",
    "\n",
    "            cumlist.append(fromnode)\n",
    "            cumlist.append(tonode)\n",
    "            cumlength += templength\n",
    "\n",
    "            #First check if tonode already exists in B. If it does, it means that a previously created path has used same route. \n",
    "            #In this case we want to use existing nodes on path rather than creating new ones.\n",
    "            if tonode in UsedNodes:\n",
    "                #If edge does not exist, then add it\n",
    "                if B.has_edge(cumlist[0], cumlist[-1]) is False:\n",
    "                    cumlist = list(dict.fromkeys(cumlist))\n",
    "                    #Get attributes for nodes and edge to add\n",
    "                    fnodeattr = H.nodes[cumlist[0]]\n",
    "                    tnodeattr = H.nodes[cumlist[-1]]\n",
    "                    edgeattr = get_edge_attributes(cumlist)\n",
    "\n",
    "                    #Add nodes and edge\n",
    "                    B.add_node(cumlist[0], **fnodeattr)\n",
    "                    B.add_node(cumlist[-1], **tnodeattr)\n",
    "                    B.add_edge(cumlist[0], cumlist[-1], **edgeattr)\n",
    "\n",
    "                    #Added nodes are appended to all UsedNodes\n",
    "                    UsedNodes.append(cumlist[0])\n",
    "                    UsedNodes.append(cumlist[-1])\n",
    "                    cumlist = []\n",
    "                    cumlength = 0\n",
    "\n",
    "\n",
    "                #Else, skip this part, but empty cummulative path and length\n",
    "                else:\n",
    "                    cumlist = []\n",
    "                    cumlength = 0\n",
    "                    pass\n",
    "                \n",
    "            elif tonode in AllCSnodes: #if next node is a CS node\n",
    "                #If edge does not exist, then add it\n",
    "                if B.has_edge(cumlist[0], cumlist[-1]) is False:\n",
    "                    cumlist = list(dict.fromkeys(cumlist))\n",
    "                    #Get attributes for nodes and edge to add\n",
    "                    fnodeattr = H.nodes[cumlist[0]]\n",
    "                    tnodeattr = H.nodes[cumlist[-1]]\n",
    "                    edgeattr = get_edge_attributes(cumlist)\n",
    "\n",
    "                    #Add nodes and edge\n",
    "                    B.add_node(cumlist[0], **fnodeattr)\n",
    "                    B.add_node(cumlist[-1], **tnodeattr)\n",
    "                    B.add_edge(cumlist[0], cumlist[-1], **edgeattr)\n",
    "\n",
    "                    #Added nodes are appended to all UsedNodes\n",
    "                    UsedNodes.append(cumlist[0])\n",
    "                    UsedNodes.append(cumlist[-1])\n",
    "                    cumlist = []\n",
    "                    cumlength = 0\n",
    "\n",
    "\n",
    "                #Else, skip this part, but empty cummulative path and length\n",
    "                else:\n",
    "                    cumlist = []\n",
    "                    cumlength = 0\n",
    "                    pass\n",
    "                \n",
    "\n",
    "            #Next, check if tonode is an OD node. If it is we will create edge from start of cumlist to the OD node.\n",
    "            elif tonode in OD_pairs_flat:\n",
    "                #If edge does not exist, then add it\n",
    "                if B.has_edge(cumlist[0], cumlist[-1]) is False:\n",
    "                    cumlist = list(dict.fromkeys(cumlist))\n",
    "                    #Get attributes for nodes and edge to add\n",
    "                    fnodeattr = H.nodes[cumlist[0]]\n",
    "                    tnodeattr = H.nodes[cumlist[-1]]\n",
    "                    edgeattr = get_edge_attributes(cumlist)\n",
    "\n",
    "                    #Add nodes and edge\n",
    "                    B.add_node(cumlist[0], **fnodeattr)\n",
    "                    B.add_node(cumlist[-1], **tnodeattr)\n",
    "                    B.add_edge(cumlist[0], cumlist[-1], **edgeattr)\n",
    "\n",
    "                    UsedNodes.append(cumlist[0])\n",
    "                    UsedNodes.append(cumlist[-1])\n",
    "                    cumlist = []\n",
    "                    cumlength = 0\n",
    "                #Else, skip this part, but empty cummulative path and length\n",
    "                else:\n",
    "                    cumlist = []\n",
    "                    cumlength = 0\n",
    "                    pass\n",
    "\n",
    "            #Next, check if the cummulative length in path is higher than the set threshold. If it is we will create a new edge in B\n",
    "            #Can consider adding an if inside here that check if there is a node within a certain radius, and skip if it is.\n",
    "            #This could prevent that nodes on completely different paths are very close or that a node is set very close to an OD node. \n",
    "            #Would then find last element in cumlist in H and get lat,lon, then use ox nearest node to find nearest node in B and finally use geopy to find distance between them. \n",
    "\n",
    "            elif cumlength >= cutoff:            \n",
    "\n",
    "\n",
    "                if B.has_edge(cumlist[0], cumlist[-1]) is False:\n",
    "                    #Remove duplicates from cumlist\n",
    "                    cumlist = list(dict.fromkeys(cumlist))\n",
    "                    distanceOD = 100000\n",
    "                    #Before we add new edge, check if destination node is within threshold/2\n",
    "                    lat = H.nodes[cumlist[-1]]['y']\n",
    "                    lon = H.nodes[cumlist[-1]]['x']\n",
    "                    latlon = (lat, lon)\n",
    "                    latdestination = H.nodes[toOD]['y']\n",
    "                    londestination = H.nodes[toOD]['x']\n",
    "\n",
    "                    #Also check if there is an already created node nearby\n",
    "                    try:\n",
    "                        potentialnode = ox.distance.nearest_nodes(B, lat, lon)\n",
    "                        clatclon = (latdestination,londestination)\n",
    "                        distanceOD = (geopy.distance.geodesic(latlon,clatclon).m)\n",
    "\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "                    # clatclon = (latdestination,londestination)\n",
    "                    # distanceOD = (geopy.distance.geodesic(latlon,clatclon).m)\n",
    "                    # distancepath = geopy.distance.geodesic(latlon, platplon).m\n",
    "\n",
    "                    if distanceOD <= cutoff /2:\n",
    "                        pass\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        #Get attributes for nodes and edge to add\n",
    "                        fnodeattr = H.nodes[cumlist[0]]\n",
    "                        tnodeattr = H.nodes[cumlist[-1]]\n",
    "                        edgeattr = get_edge_attributes(cumlist)\n",
    "\n",
    "                        #Add nodes and edge\n",
    "                        B.add_node(cumlist[0], **fnodeattr)\n",
    "                        B.add_node(cumlist[-1], **tnodeattr)\n",
    "                        B.add_edge(cumlist[0], cumlist[-1], **edgeattr)\n",
    "\n",
    "                        UsedNodes.append(cumlist[0])\n",
    "                        UsedNodes.append(cumlist[-1])                \n",
    "                        cumlist = []\n",
    "                        cumlength = 0\n",
    "\n",
    "                #Else, skip this part, but empty cummulative path and length\n",
    "                else:\n",
    "                    cumlist = []\n",
    "                    cumlength = 0\n",
    "                    pass\n",
    "\n",
    "        bar.update(counter)\n",
    "        counter+=1\n",
    "\n",
    "    bar.finish()\n",
    "\n",
    "    #Set OD=1 for all O-D nodes and CS=1 for all current CS nodes. \n",
    "    nx.set_node_attributes(B, 0, 'OD')\n",
    "    nx.set_node_attributes(B, 0, 'CS')\n",
    "\n",
    "    attrs = {}\n",
    "    for i in OD_pairs_flat:\n",
    "        O = i\n",
    "        attrs[i] = {'OD':1}\n",
    "    nx.set_node_attributes(B, attrs)\n",
    "    \n",
    "    attrs = {}\n",
    "    for i in AllCSnodes:\n",
    "        O = i\n",
    "        attrs[i] = {'CS':1}\n",
    "    nx.set_node_attributes(B, attrs)\n",
    "    \n",
    "    \n",
    "    print(\"Complete!\")\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'networkx' has no attribute 'write_gpickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anton\\Desktop\\Master-Oppgave\\Kode\\apert\\dataprep.ipynb Cell 10\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anton/Desktop/Master-Oppgave/Kode/apert/dataprep.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m B \u001b[39m=\u001b[39m shorten_edges_v2(H, OD, \u001b[39m10000\u001b[39m) \u001b[39m#Select cut-off value\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/anton/Desktop/Master-Oppgave/Kode/apert/dataprep.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m nx\u001b[39m.\u001b[39;49mwrite_gpickle(B,\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39manton\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDesktop\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mMaster-Oppgave\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mKode\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mapert\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mB10000.gpickle\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anton/Desktop/Master-Oppgave/Kode/apert/dataprep.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m B \u001b[39m=\u001b[39m shorten_edges_v2(H, OD, \u001b[39m2000\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anton/Desktop/Master-Oppgave/Kode/apert/dataprep.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m nx\u001b[39m.\u001b[39mwrite_gpickle(B,\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39manton\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDesktop\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mMaster-Oppgave\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mKode\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mapert\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mB2000.gpickle\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'networkx' has no attribute 'write_gpickle'"
     ]
    }
   ],
   "source": [
    "B = shorten_edges_v2(H, OD, 10000) #Select cut-off value\n",
    "nx.write_gpickle(B,r\"C:\\Users\\anton\\Desktop\\Master-Oppgave\\Kode\\apert\\data\\B10000.gpickle\")\n",
    "B = shorten_edges_v2(H, OD, 2000)\n",
    "nx.write_gpickle(B,r\"C:\\Users\\anton\\Desktop\\Master-Oppgave\\Kode\\apert\\data\\B2000.gpickle\")\n",
    "B = shorten_edges_v2(H, OD, 5000)\n",
    "nx.write_gpickle(B,r\"C:\\Users\\anton\\Desktop\\Master-Oppgave\\Kode\\apert\\data\\B5000.gpickle\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
